{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GranD DamList and Inflow time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rpy2.robjects import r\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "import tools\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Row-major order shapefile of the 0.5 degree global graticule\n",
    "We change the cru_id of \"cru_ts.shp\" from Column-major order to Row-major order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    old = gpd.read_file('./data/cru_ts.shp')\n",
    "    subs = np.unravel_index(old.cru_id-1, [360,720], 'F')\n",
    "    reidx = np.ravel_multi_index(subs, [360,720], order='C')\n",
    "    new = old.copy()\n",
    "    new['cru_id'] = reidx\n",
    "    new = new.sort_values('cru_id').reset_index(drop=True)\n",
    "    new.to_file('./data/cru_reindexed.shp') # Validated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate DamList with global index and Inflow data from Rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read RData\n",
    "rf = r['load']('./data/rdata/inflows_MCM_1958_20181126.Rdata')\n",
    "rf = r['new_inflows_1958']\n",
    "data = np.zeros([len(rf),516+1])\n",
    "for i in range(len(rf)):\n",
    "#     data[i,0] = pandas2ri.ri2py_intvector(rf[i][0])\n",
    "#     data[i,1:] = pandas2ri.ri2py_intvector(rf[i][3])\n",
    "    data[i,0] = rf[i][0]\n",
    "    data[i,1:] = rf[i][3]\n",
    "\n",
    "# Convert to DataFrame\n",
    "damList = data[:,0].astype(int)\n",
    "mondex = pd.period_range('{:04d}-{:02d}'.format(1958,1), periods=516, freq='M')\n",
    "dfFlowDams = pd.DataFrame(data=data[:,1:].T, index=mondex, columns=damList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-007148f908e1>:3: FutureWarning: Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "  xl = pd.ExcelFile(fn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    6,    24,    25, ...,  2078,  4795,  6521],\n",
       "       [48355, 57708, 57708, ..., 65010, 85477, 79115]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Latitude and Longitude for the selected GranD dams\n",
    "fn = os.path.join('./data/grand1593_uparea.xlsx')\n",
    "xl = pd.ExcelFile(fn)\n",
    "df = xl.parse('cruidToLatLon')\n",
    "gridIndx = df.cruid_aligned.values - 1\n",
    "\n",
    "# Get upstream areas at the grids of interest\n",
    "subs = np.unravel_index(gridIndx, [360,720], 'F')\n",
    "ind_dams = np.ravel_multi_index(subs, [360,720], order='C')\n",
    "ind_dams = np.vstack((df.grand_no, ind_dams))\n",
    "\n",
    "# Reorder \"ind_dams\" to be matched with \"damList\"\n",
    "order = np.array([np.argwhere(ind_dams[0,:] == did)[0][0] for did in damList])\n",
    "ind_dams = ind_dams[:,order]\n",
    "ind_dams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/dfFlowDams.hdf is saved.\n",
      "./data/ind_dams.npz is saved.\n"
     ]
    }
   ],
   "source": [
    "# Save Data (dfFlowDams, ind_dams)\n",
    "if True:\n",
    "    filn = './data/dfFlowDams.hdf'\n",
    "#     dfFlowDams.to_hdf(filn, key='df', complib='blosc:zstd', complevel=9)\n",
    "    dfFlowDams.to_hdf(filn, key='df')\n",
    "    print('%s is saved.' % filn)\n",
    "    filn = './data/ind_dams'\n",
    "    np.savez_compressed(filn, ind_dams = ind_dams)\n",
    "    print('%s.npz is saved.' % filn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
